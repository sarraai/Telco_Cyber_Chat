# Qdrant
QDRANT_URL=https://e864839c-9b30-44c5-ba24-2e5cb5546efd.us-west-2-0.aws.cloud.qdrant.io:6333
QDRANT_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJhY2Nlc3MiOiJtIn0.rzLElfT2yp2XfLmVo0p8Qs2TUnyxcLaR8l2pmJgC9NI
QDRANT_COLLECTION=Telco_CyberChat
DENSE_FIELD=dense
SPARSE_FIELD=sparse

# Models
RERANKER_MODEL=BAAI/bge-reranker-large
JUDGE_ID=BAAI/JudgeLM-7B-v1.0
USE_FP16=true

# LangSmith
LANGSMITH_API_KEY=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
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT=https://api.smith.langchain.com

# === LOCAL INFERENCE MODE ===
USE_REMOTE_HF=false
ALLOW_LOCAL_LLM=true

# HuggingFace token (REQUIRED for downloading models)
HF_TOKEN=hf_your_actual_token_here

# Local model IDs
MODEL_ID=fdtn-ai/Foundation-Sec-8B-Instruct
GUARD_ID=meta-llama/Llama-Guard-3-8B
BGE_MODEL_ID=BAAI/bge-m3

# Model cache (optional but recommended)
TRANSFORMERS_CACHE=/tmp/model_cache
HF_HOME=/tmp/huggingface

# Job isolation
BG_JOB_ISOLATED_LOOPS=true

#cisco scraping
CLIENT_ID = ucprtmc76uqkhda36q26z8f9
CLIENT_SECRET = gNjqQMquNyejxerJ2SYFPdqX
